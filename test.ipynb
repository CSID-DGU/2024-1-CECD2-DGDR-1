{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17bdc110-28b4-401f-a84e-47c8af116642",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving notices: ...working... done\n",
      "Collecting package metadata (current_repodata.json): - WARNING conda.models.version:get_matcher(546): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.7.1.*, but conda is ignoring the .* and treating it as 1.7.1\n",
      "done\n",
      "Solving environment: \\ \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - conda-forge/noarch::bleach==6.1.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::importlib_metadata==7.1.0=hd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyter_client==8.6.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::s3transfer==0.10.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::bokeh==3.4.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::ipykernel==6.29.3=pyhd33586a_0\n",
      "  - conda-forge/linux-64::matplotlib-base==3.8.3=py310h62c0568_0\n",
      "  - conda-forge/linux-64::statsmodels==0.14.1=py310h1f7b6fc_0\n",
      "  - conda-forge/noarch::nbclient==0.10.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::seaborn-base==0.13.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbconvert-core==7.16.3=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::seaborn==0.13.2=hd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyter_server==2.13.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyter-lsp==2.2.4=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyterlab_server==2.25.4=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::notebook-shim==0.2.4=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyterlab==4.1.5=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::notebook==7.1.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::captum==0.6.0=pyhd8ed1ab_0\n",
      "  - https://aws-ml-conda.s3.us-west-2.amazonaws.com/linux-64::pytorch==2.1.0=aws_py3.10_cuda12.1_cudnn8.9.2_0\n",
      "  - https://aws-ml-conda.s3.us-west-2.amazonaws.com/linux-64::torchaudio==2.1.0=py310_cu121\n",
      "  - https://aws-ml-conda.s3.us-west-2.amazonaws.com/linux-64::torchdata==0.7.0=py310\n",
      "  - https://aws-ml-conda.s3.us-west-2.amazonaws.com/linux-64::torchtriton==2.1.0=py310\n",
      "  - https://aws-ml-conda.s3.us-west-2.amazonaws.com/linux-64::torchvision==0.16.0=py310_cu121\n",
      "  - https://aws-ml-conda.s3.us-west-2.amazonaws.com/linux-64::torchtext==0.16.0=py310\n",
      "done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 24.5.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.5.0\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ec2-user/anaconda3/envs/pytorch_p310\n",
      "\n",
      "  added / updated specs:\n",
      "    - faiss-gpu\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    boto3-1.34.116             |     pyhd8ed1ab_0          79 KB  conda-forge\n",
      "    botocore-1.34.116          |pyge310_1234567_0         6.7 MB  conda-forge\n",
      "    cudatoolkit-11.8.0         |      h4ba93d1_13       682.5 MB  conda-forge\n",
      "    faiss-1.7.4                |py310cuda112hae2f2aa_0_cuda         1.5 MB  conda-forge\n",
      "    faiss-gpu-1.7.4            |       h788eb59_0          19 KB  conda-forge\n",
      "    libfaiss-1.7.4             |cuda112hb18a002_0_cuda        68.0 MB  conda-forge\n",
      "    libfaiss-avx2-1.7.4        |cuda112h1234567_0_cuda        68.1 MB  conda-forge\n",
      "    openssl-3.3.0              |       h4ab18f5_3         2.8 MB  conda-forge\n",
      "    pandas-2.2.2               |  py310hf9f9076_1        12.4 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       841.9 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  boto3              conda-forge/noarch::boto3-1.34.116-pyhd8ed1ab_0 \n",
      "  botocore           conda-forge/noarch::botocore-1.34.116-pyge310_1234567_0 \n",
      "  cudatoolkit        conda-forge/linux-64::cudatoolkit-11.8.0-h4ba93d1_13 \n",
      "  faiss              conda-forge/linux-64::faiss-1.7.4-py310cuda112hae2f2aa_0_cuda \n",
      "  faiss-gpu          conda-forge/linux-64::faiss-gpu-1.7.4-h788eb59_0 \n",
      "  importlib-metadata conda-forge/noarch::importlib-metadata-7.1.0-pyha770c72_0 \n",
      "  libfaiss           conda-forge/linux-64::libfaiss-1.7.4-cuda112hb18a002_0_cuda \n",
      "  libfaiss-avx2      conda-forge/linux-64::libfaiss-avx2-1.7.4-cuda112h1234567_0_cuda \n",
      "  packaging          conda-forge/noarch::packaging-24.0-pyhd8ed1ab_0 \n",
      "  pandas             conda-forge/linux-64::pandas-2.2.2-py310hf9f9076_1 \n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  openssl                                  3.2.1-hd590300_1 --> 3.3.0-h4ab18f5_3 \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "boto3-1.34.116       | 79 KB     |                                       |   0% \n",
      "cudatoolkit-11.8.0   | 682.5 MB  |                                       |   0% \u001b[A\n",
      "\n",
      "libfaiss-avx2-1.7.4  | 68.1 MB   |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "botocore-1.34.116    | 6.7 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "faiss-1.7.4          | 1.5 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "faiss-gpu-1.7.4      | 19 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-3.3.0        | 2.8 MB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pandas-2.2.2         | 12.4 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  |                                       |   0% \u001b[A\n",
      "\n",
      "\n",
      "botocore-1.34.116    | 6.7 MB    | #####                                 |  14% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "faiss-1.7.4          | 1.5 MB    | ##3                                   |   6% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "boto3-1.34.116       | 79 KB     | #######5                              |  20% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "faiss-gpu-1.7.4      | 19 KB     | ###############################8      |  86% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | 2                                     |   1% \u001b[A\n",
      "\n",
      "\n",
      "botocore-1.34.116    | 6.7 MB    | ##########################8           |  72% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libfaiss-avx2-1.7.4  | 68.1 MB   | #6                                    |   4% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-3.3.0        | 2.8 MB    | 2                                     |   1% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "faiss-gpu-1.7.4      | 19 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libfaiss-avx2-1.7.4  | 68.1 MB   | ##6                                   |   7% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   | 9                                     |   3% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-3.3.0        | 2.8 MB    | #######################               |  62% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | 3                                     |   1% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pandas-2.2.2         | 12.4 MB   |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libfaiss-avx2-1.7.4  | 68.1 MB   | ###8                                  |  10% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   | ##2                                   |   6% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | 5                                     |   1% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pandas-2.2.2         | 12.4 MB   | #######3                              |  20% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "boto3-1.34.116       | 79 KB     | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   | ###4                                  |   9% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | 6                                     |   2% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pandas-2.2.2         | 12.4 MB   | #############7                        |  37% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libfaiss-avx2-1.7.4  | 68.1 MB   | ######2                               |  17% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   | ####6                                 |  12% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | 7                                     |   2% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pandas-2.2.2         | 12.4 MB   | ####################2                 |  55% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libfaiss-avx2-1.7.4  | 68.1 MB   | #######5                              |  20% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   | #####8                                |  16% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pandas-2.2.2         | 12.4 MB   | ###########################           |  73% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | 9                                     |   2% \u001b[A\n",
      "\n",
      "libfaiss-avx2-1.7.4  | 68.1 MB   | ########7                             |  24% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   | #######1                              |  19% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pandas-2.2.2         | 12.4 MB   | #################################9    |  92% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #                                     |   3% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "faiss-1.7.4          | 1.5 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "faiss-1.7.4          | 1.5 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libfaiss-avx2-1.7.4  | 68.1 MB   | ##########                            |  27% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   | ########3                             |  23% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #1                                    |   3% \u001b[A\n",
      "\n",
      "libfaiss-avx2-1.7.4  | 68.1 MB   | ###########1                          |  30% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   | #########6                            |  26% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #2                                    |   3% \u001b[A\n",
      "\n",
      "libfaiss-avx2-1.7.4  | 68.1 MB   | ############6                         |  34% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   | ##########9                           |  30% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #4                                    |   4% \u001b[A\n",
      "\n",
      "libfaiss-avx2-1.7.4  | 68.1 MB   | #############9                        |  38% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   | ############3                         |  33% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-3.3.0        | 2.8 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "openssl-3.3.0        | 2.8 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #5                                    |   4% \u001b[A\n",
      "\n",
      "libfaiss-avx2-1.7.4  | 68.1 MB   | ###############5                      |  42% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   | #############9                        |  38% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #7                                    |   5% \u001b[A\n",
      "\n",
      "libfaiss-avx2-1.7.4  | 68.1 MB   | #################2                    |  47% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   | ###############6                      |  42% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #8                                    |   5% \u001b[A\n",
      "\n",
      "libfaiss-avx2-1.7.4  | 68.1 MB   | ##################8                   |  51% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   | #################2                    |  47% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ##                                    |   6% \u001b[A\n",
      "\n",
      "libfaiss-avx2-1.7.4  | 68.1 MB   | ####################4                 |  55% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   | ##################9                   |  51% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ##2                                   |   6% \u001b[A\n",
      "\n",
      "libfaiss-avx2-1.7.4  | 68.1 MB   | ######################1               |  60% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   | ####################6                 |  56% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ##4                                   |   7% \u001b[A\n",
      "\n",
      "libfaiss-avx2-1.7.4  | 68.1 MB   | #######################8              |  65% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   | ######################3               |  60% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ##5                                   |   7% \u001b[A\n",
      "\n",
      "libfaiss-avx2-1.7.4  | 68.1 MB   | #########################5            |  69% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   | ########################              |  65% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ##7                                   |   8% \u001b[A\n",
      "\n",
      "libfaiss-avx2-1.7.4  | 68.1 MB   | ###########################3          |  74% \u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ##9                                   |   8% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   | #########################6            |  69% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libfaiss-avx2-1.7.4  | 68.1 MB   | #############################         |  79% \u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ###1                                  |   9% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   | ###########################2          |  74% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libfaiss-avx2-1.7.4  | 68.1 MB   | ##############################7       |  83% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   | #############################         |  78% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ###3                                  |   9% \u001b[A\n",
      "\n",
      "libfaiss-avx2-1.7.4  | 68.1 MB   | ################################5     |  88% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   | ##############################6       |  83% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ###5                                  |  10% \u001b[A\n",
      "\n",
      "libfaiss-avx2-1.7.4  | 68.1 MB   | ##################################2   |  93% \u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ###7                                  |  10% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   | ################################2     |  87% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "libfaiss-avx2-1.7.4  | 68.1 MB   | ####################################  |  97% \u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ###8                                  |  11% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   | #################################9    |  92% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ####                                  |  11% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   | ###################################4  |  96% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ####2                                 |  11% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ####4                                 |  12% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ####7                                 |  13% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ####9                                 |  13% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #####1                                |  14% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #####4                                |  15% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #####6                                |  15% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #####8                                |  16% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ######1                               |  17% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ######3                               |  17% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ######6                               |  18% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ######8                               |  19% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #######1                              |  19% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #######3                              |  20% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #######5                              |  21% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #######8                              |  21% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ########                              |  22% \u001b[A\n",
      "\n",
      "\n",
      "botocore-1.34.116    | 6.7 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ########3                             |  23% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ########5                             |  23% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ########8                             |  24% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #########1                            |  25% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #########3                            |  25% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #########6                            |  26% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #########9                            |  27% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ##########2                           |  28% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ##########5                           |  28% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ##########8                           |  29% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ###########                           |  30% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ###########3                          |  31% \u001b[A\n",
      "\n",
      "libfaiss-avx2-1.7.4  | 68.1 MB   | ##################################### | 100% \u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ###########6                          |  32% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "pandas-2.2.2         | 12.4 MB   | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ############                          |  33% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ############3                         |  33% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ############6                         |  34% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "libfaiss-1.7.4       | 68.0 MB   | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #############1                        |  35% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #############4                        |  36% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #############7                        |  37% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ##############2                       |  38% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ##############5                       |  39% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ##############9                       |  40% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ###############2                      |  41% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ###############5                      |  42% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ################                      |  43% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ################3                     |  44% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ################7                     |  45% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #################1                    |  46% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #################5                    |  47% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #################8                    |  48% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ##################1                   |  49% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ##################4                   |  50% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ##################6                   |  50% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ###################                   |  52% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ###################3                  |  52% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ###################6                  |  53% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ####################                  |  54% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ####################4                 |  55% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ####################7                 |  56% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #####################                 |  57% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #####################3                |  58% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #####################6                |  58% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #####################9                |  59% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ######################1               |  60% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ######################4               |  61% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ######################7               |  61% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #######################1              |  63% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #######################5              |  64% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #######################9              |  65% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ########################2             |  66% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ########################5             |  66% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ########################8             |  67% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #########################             |  68% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #########################3            |  68% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #########################6            |  69% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #########################9            |  70% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ##########################1           |  71% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ##########################3           |  71% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ##########################5           |  72% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ##########################7           |  72% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ##########################9           |  73% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ###########################1          |  74% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ###########################4          |  74% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ###########################5          |  75% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ###########################7          |  75% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ###########################9          |  76% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ############################7         |  78% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #############################2        |  79% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #############################8        |  81% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ##############################3       |  82% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ##############################7       |  83% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ###############################1      |  84% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ###############################9      |  86% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ################################4     |  88% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ################################8     |  89% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #################################2    |  90% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | #################################7    |  91% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ##################################1   |  92% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ##################################8   |  94% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ###################################2  |  95% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ###################################6  |  96% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ####################################1 |  98% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ####################################5 |  99% \u001b[A\n",
      "cudatoolkit-11.8.0   | 682.5 MB  | ####################################9 | 100% \u001b[A\n",
      "                                                                                \u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: \\ By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html\n",
      "\n",
      "done\n",
      "Collecting package metadata (current_repodata.json): / WARNING conda.models.version:get_matcher(546): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.7.1.*, but conda is ignoring the .* and treating it as 1.7.1\n",
      "done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): \\ WARNING conda.models.version:get_matcher(546): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.9.0.*, but conda is ignoring the .* and treating it as 1.9.0\n",
      "WARNING conda.models.version:get_matcher(546): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.8.0.*, but conda is ignoring the .* and treating it as 1.8.0\n",
      "WARNING conda.models.version:get_matcher(546): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.6.0.*, but conda is ignoring the .* and treating it as 1.6.0\n",
      "done\n",
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 23.3.1\n",
      "  latest version: 24.5.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c conda-forge conda\n",
      "\n",
      "Or to minimize the number of packages updated during conda update use\n",
      "\n",
      "     conda install conda=24.5.0\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ec2-user/anaconda3/envs/pytorch_p310\n",
      "\n",
      "  added / updated specs:\n",
      "    - mkl=2021\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    blas-1.0                   |              mkl           1 KB  conda-forge\n",
      "    libblas-3.9.0              |   12_linux64_mkl          12 KB  conda-forge\n",
      "    libcblas-3.9.0             |   12_linux64_mkl          12 KB  conda-forge\n",
      "    liblapack-3.9.0            |   12_linux64_mkl          12 KB  conda-forge\n",
      "    mkl-2021.4.0               |     h8d4b97c_729       219.1 MB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       219.1 MB\n",
      "\n",
      "The following packages will be REMOVED:\n",
      "\n",
      "  blas-devel-3.9.0-16_linux64_mkl\n",
      "  liblapacke-3.9.0-16_linux64_mkl\n",
      "  mkl-devel-2022.1.0-ha770c72_916\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  mkl                           ::mkl-2022.1.0-h84fe81f_915 --> conda-forge::mkl-2021.4.0-h8d4b97c_729 \n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  blas                                            2.116-mkl --> 1.0-mkl \n",
      "  libblas                              3.9.0-16_linux64_mkl --> 3.9.0-12_linux64_mkl \n",
      "  libcblas                             3.9.0-16_linux64_mkl --> 3.9.0-12_linux64_mkl \n",
      "  liblapack                            3.9.0-16_linux64_mkl --> 3.9.0-12_linux64_mkl \n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "mkl-2021.4.0         | 219.1 MB  |                                       |   0% \n",
      "libblas-3.9.0        | 12 KB     |                                       |   0% \u001b[A\n",
      "\n",
      "liblapack-3.9.0      | 12 KB     |                                       |   0% \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "libcblas-3.9.0       | 12 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "blas-1.0             | 1 KB      |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "liblapack-3.9.0      | 12 KB     | ##################################### | 100% \u001b[A\u001b[A\n",
      "\n",
      "liblapack-3.9.0      | 12 KB     | ##################################### | 100% \u001b[A\u001b[A\n",
      "libblas-3.9.0        | 12 KB     | ##################################### | 100% \u001b[A\n",
      "libblas-3.9.0        | 12 KB     | ##################################### | 100% \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "blas-1.0             | 1 KB      | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "blas-1.0             | 1 KB      | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "libcblas-3.9.0       | 12 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Collecting transformers==4.17.0\n",
      "  Downloading transformers-4.17.0-py3-none-any.whl.metadata (67 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.17.0) (3.13.3)\n",
      "Collecting huggingface-hub<1.0,>=0.1.0 (from transformers==4.17.0)\n",
      "  Downloading huggingface_hub-0.23.2-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.17.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.17.0) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.17.0) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.17.0)\n",
      "  Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.17.0) (2.31.0)\n",
      "Collecting sacremoses (from transformers==4.17.0)\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting tokenizers!=0.11.3,>=0.11.1 (from transformers==4.17.0)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from transformers==4.17.0) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.17.0) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers==4.17.0) (4.10.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.17.0) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.17.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.17.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.17.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests->transformers==4.17.0) (2024.2.2)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sacremoses->transformers==4.17.0) (8.1.7)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sacremoses->transformers==4.17.0) (1.3.2)\n",
      "Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.23.2-py3-none-any.whl (401 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.7/401.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.1/775.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m83.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: regex, sacremoses, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.23.2 regex-2024.5.15 sacremoses-0.1.1 tokenizers-0.19.1 transformers-4.17.0\n",
      "Collecting kobert_tokenizer (from -r requirements.txt (line 8))\n",
      "  Cloning https://github.com/SKTBrain/KoBERT.git to /tmp/pip-install-zbxmv609/kobert-tokenizer_01e5680047274ebeb0c882bfa018b8b2\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/SKTBrain/KoBERT.git /tmp/pip-install-zbxmv609/kobert-tokenizer_01e5680047274ebeb0c882bfa018b8b2\n",
      "  Resolved https://github.com/SKTBrain/KoBERT.git to commit 47a69af87928fc24e20f571fe10c3cc9dd9af9a3\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sentencepiece (from -r requirements.txt (line 1))\n",
      "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting pytest (from -r requirements.txt (line 2))\n",
      "  Downloading pytest-8.2.1-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting wandb (from -r requirements.txt (line 3))\n",
      "  Downloading wandb-0.17.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from -r requirements.txt (line 4)) (4.66.2)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (1.26.4)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from -r requirements.txt (line 6)) (1.12.0)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (1.5.3)\n",
      "Collecting wikiextractor (from -r requirements.txt (line 9))\n",
      "  Downloading wikiextractor-3.0.6-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting iniconfig (from pytest->-r requirements.txt (line 2))\n",
      "  Downloading iniconfig-2.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: packaging in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pytest->-r requirements.txt (line 2)) (21.3)\n",
      "Collecting pluggy<2.0,>=1.5 (from pytest->-r requirements.txt (line 2))\n",
      "  Using cached pluggy-1.5.0-py3-none-any.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pytest->-r requirements.txt (line 2)) (1.2.0)\n",
      "Requirement already satisfied: tomli>=1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pytest->-r requirements.txt (line 2)) (2.0.1)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 3)) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 3))\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 3))\n",
      "  Using cached GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: platformdirs in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 3)) (4.2.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 3)) (4.25.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 3)) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 3)) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 3)) (2.31.0)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 3))\n",
      "  Downloading sentry_sdk-2.3.1-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb->-r requirements.txt (line 3))\n",
      "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from wandb->-r requirements.txt (line 3)) (69.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 7)) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 7)) (2024.1)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 3)) (1.16.0)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 3))\n",
      "  Using cached gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 3)) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 3)) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 3)) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 3)) (2024.2.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from packaging->pytest->-r requirements.txt (line 2)) (3.1.2)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 3))\n",
      "  Using cached smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pytest-8.2.1-py3-none-any.whl (339 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m339.6/339.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading wandb-0.17.0-py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading wikiextractor-3.0.6-py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m653.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Using cached GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
      "Using cached pluggy-1.5.0-py3-none-any.whl (20 kB)\n",
      "Downloading sentry_sdk-2.3.1-py2.py3-none-any.whl (289 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.0/289.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading iniconfig-2.0.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Using cached gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
      "Using cached smmap-5.0.1-py3-none-any.whl (24 kB)\n",
      "Building wheels for collected packages: kobert_tokenizer\n",
      "  Building wheel for kobert_tokenizer (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kobert_tokenizer: filename=kobert_tokenizer-0.1-py3-none-any.whl size=4633 sha256=6e985ea7ed9ce89d647904ba228c665580f1832db83cb23fe352ca170b8fe94b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-uxxfksxh/wheels/e9/1a/3f/a864970e8a169c176befa3c4a1e07aa612f69195907a4045fe\n",
      "Successfully built kobert_tokenizer\n",
      "Installing collected packages: sentencepiece, kobert_tokenizer, wikiextractor, smmap, setproctitle, sentry-sdk, pluggy, iniconfig, docker-pycreds, pytest, gitdb, gitpython, wandb\n",
      "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 iniconfig-2.0.0 kobert_tokenizer-0.1 pluggy-1.5.0 pytest-8.2.1 sentencepiece-0.2.0 sentry-sdk-2.3.1 setproctitle-1.3.3 smmap-5.0.1 wandb-0.17.0 wikiextractor-3.0.6\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "#!pip install torch==1.10.1+cu111 -f https://download.pytorch.org/whl/cu111/torch_stable.html\n",
    "!conda install faiss-gpu -c pytorch -y\n",
    "!conda install mkl=2021 -y\n",
    "!{sys.executable} -m pip install -U transformers==4.17.0\n",
    "#!{sys.executable} -m pip install -U transformers==4.17.0\n",
    "!{sys.executable} -m pip install -r requirements.txt\n",
    "!{sys.executable} -m pip install git+https://github.com/SKTBrain/KoBERT.git#egg=kobert_tokenizer&subdirectory=kobert_hf\n",
    "\n",
    "#!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "278a144e-ed40-49fb-a025-1b62339ade77",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.41s/it]\n",
      "100%|████████████████████████████████████████████| 2/2 [00:00<00:00, 795.13it/s]\n"
     ]
    }
   ],
   "source": [
    "!python chunk_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4862122c-17c5-4c82-a6cb-e0f6cdd23f62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:01<00:00,  1.38s/it]\n",
      "100%|███████████████████████████████████████████| 1/1 [00:00<00:00, 5115.00it/s]\n"
     ]
    }
   ],
   "source": [
    "!python chunk_inference_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d89070ad-b7e3-443b-836e-ffe3b3dfc46a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n",
      "epoch 1 batch: 100%|██████████████████████████████| 1/1 [00:00<00:00,  1.19it/s]\n",
      "epoch 2 batch: 100%|██████████████████████████████| 1/1 [00:00<00:00,  5.06it/s]\n",
      "epoch 3 batch: 100%|██████████████████████████████| 1/1 [00:00<00:00,  4.45it/s]\n",
      "epoch 4 batch: 100%|██████████████████████████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "epoch 5 batch: 100%|██████████████████████████████| 1/1 [00:00<00:00,  4.55it/s]\n",
      "epoch 6 batch: 100%|██████████████████████████████| 1/1 [00:00<00:00,  4.69it/s]\n",
      "epoch 7 batch: 100%|██████████████████████████████| 1/1 [00:00<00:00,  4.32it/s]\n",
      "epoch 8 batch: 100%|██████████████████████████████| 1/1 [00:00<00:00,  4.49it/s]\n",
      "epoch 9 batch: 100%|██████████████████████████████| 1/1 [00:00<00:00,  4.45it/s]\n",
      "epoch 10 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "epoch 11 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.53it/s]\n",
      "epoch 12 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.05it/s]\n",
      "epoch 13 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.25it/s]\n",
      "epoch 14 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.38it/s]\n",
      "epoch 15 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.55it/s]\n",
      "epoch 16 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.44it/s]\n",
      "epoch 17 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.49it/s]\n",
      "epoch 18 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.46it/s]\n",
      "epoch 19 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.41it/s]\n",
      "epoch 20 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.40it/s]\n",
      "epoch 21 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.22it/s]\n",
      "epoch 22 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.54it/s]\n",
      "epoch 23 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.39it/s]\n",
      "epoch 24 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.42it/s]\n",
      "epoch 25 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "epoch 26 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.11it/s]\n",
      "epoch 27 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "epoch 28 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.16it/s]\n",
      "epoch 29 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.21it/s]\n",
      "epoch 30 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.43it/s]\n",
      "epoch 31 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.47it/s]\n",
      "epoch 32 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.37it/s]\n",
      "epoch 33 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.40it/s]\n",
      "epoch 34 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.46it/s]\n",
      "epoch 35 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.46it/s]\n",
      "epoch 36 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.23it/s]\n",
      "epoch 37 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.50it/s]\n",
      "epoch 38 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.55it/s]\n",
      "epoch 39 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.32it/s]\n",
      "epoch 40 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.54it/s]\n",
      "epoch 41 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.56it/s]\n",
      "epoch 42 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.45it/s]\n",
      "epoch 43 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.47it/s]\n",
      "epoch 44 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.47it/s]\n",
      "epoch 45 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.69it/s]\n",
      "epoch 46 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.42it/s]\n",
      "epoch 47 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.17it/s]\n",
      "epoch 48 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.12it/s]\n",
      "epoch 49 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.32it/s]\n",
      "epoch 50 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.36it/s]\n",
      "epoch 51 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.52it/s]\n",
      "epoch 52 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.28it/s]\n",
      "epoch 53 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.51it/s]\n",
      "epoch 54 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.31it/s]\n",
      "epoch 55 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.53it/s]\n",
      "epoch 56 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.28it/s]\n",
      "epoch 57 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.36it/s]\n",
      "epoch 58 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "epoch 59 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.61it/s]\n",
      "epoch 60 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.65it/s]\n",
      "epoch 61 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.36it/s]\n",
      "epoch 62 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.58it/s]\n",
      "epoch 63 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.56it/s]\n",
      "epoch 64 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.21it/s]\n",
      "epoch 65 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "epoch 66 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.31it/s]\n",
      "epoch 67 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.49it/s]\n",
      "epoch 68 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.84it/s]\n",
      "epoch 69 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.63it/s]\n",
      "epoch 70 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.23it/s]\n",
      "epoch 71 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.47it/s]\n",
      "epoch 72 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.40it/s]\n",
      "epoch 73 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.28it/s]\n",
      "epoch 74 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.34it/s]\n",
      "epoch 75 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.46it/s]\n",
      "epoch 76 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.24it/s]\n",
      "epoch 77 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.32it/s]\n",
      "epoch 78 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.77it/s]\n",
      "epoch 79 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.49it/s]\n",
      "epoch 80 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.19it/s]\n",
      "epoch 81 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.69it/s]\n",
      "epoch 82 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.04it/s]\n",
      "epoch 83 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.30it/s]\n",
      "epoch 84 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.53it/s]\n",
      "epoch 85 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.43it/s]\n",
      "epoch 86 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.41it/s]\n",
      "epoch 87 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.04it/s]\n",
      "epoch 88 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.25it/s]\n",
      "epoch 89 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.32it/s]\n",
      "epoch 90 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.45it/s]\n",
      "epoch 91 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.66it/s]\n",
      "epoch 92 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.19it/s]\n",
      "epoch 93 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.41it/s]\n",
      "epoch 94 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.69it/s]\n",
      "epoch 95 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.38it/s]\n",
      "epoch 96 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.33it/s]\n",
      "epoch 97 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.43it/s]\n",
      "epoch 98 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.43it/s]\n",
      "epoch 99 batch: 100%|█████████████████████████████| 1/1 [00:00<00:00,  4.54it/s]\n",
      "epoch 100 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.57it/s]\n",
      "epoch 101 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.22it/s]\n",
      "epoch 102 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.51it/s]\n",
      "epoch 103 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.16it/s]\n",
      "epoch 104 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.30it/s]\n",
      "epoch 105 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.23it/s]\n",
      "epoch 106 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.32it/s]\n",
      "epoch 107 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.21it/s]\n",
      "epoch 108 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.43it/s]\n",
      "epoch 109 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.53it/s]\n",
      "epoch 110 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.28it/s]\n",
      "epoch 111 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.23it/s]\n",
      "epoch 112 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.56it/s]\n",
      "epoch 113 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.38it/s]\n",
      "epoch 114 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.56it/s]\n",
      "epoch 115 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.21it/s]\n",
      "epoch 116 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.41it/s]\n",
      "epoch 117 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.26it/s]\n",
      "epoch 118 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.30it/s]\n",
      "epoch 119 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.62it/s]\n",
      "epoch 120 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.44it/s]\n",
      "epoch 121 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.30it/s]\n",
      "epoch 122 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.30it/s]\n",
      "epoch 123 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "epoch 124 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.25it/s]\n",
      "epoch 125 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.19it/s]\n",
      "epoch 126 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.29it/s]\n",
      "epoch 127 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.22it/s]\n",
      "epoch 128 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.32it/s]\n",
      "epoch 129 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.24it/s]\n",
      "epoch 130 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.43it/s]\n",
      "epoch 131 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.69it/s]\n",
      "epoch 132 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.38it/s]\n",
      "epoch 133 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.24it/s]\n",
      "epoch 134 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.64it/s]\n",
      "epoch 135 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.30it/s]\n",
      "epoch 136 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "epoch 137 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.37it/s]\n",
      "epoch 138 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.41it/s]\n",
      "epoch 139 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.41it/s]\n",
      "epoch 140 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.30it/s]\n",
      "epoch 141 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "epoch 142 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.20it/s]\n",
      "epoch 143 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.23it/s]\n",
      "epoch 144 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.47it/s]\n",
      "epoch 145 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.35it/s]\n",
      "epoch 146 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.34it/s]\n",
      "epoch 147 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.53it/s]\n",
      "epoch 148 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.60it/s]\n",
      "epoch 149 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.33it/s]\n",
      "epoch 150 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.21it/s]\n",
      "epoch 151 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.36it/s]\n",
      "epoch 152 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.52it/s]\n",
      "epoch 153 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.44it/s]\n",
      "epoch 154 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.38it/s]\n",
      "epoch 155 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.42it/s]\n",
      "epoch 156 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.28it/s]\n",
      "epoch 157 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.60it/s]\n",
      "epoch 158 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "epoch 159 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.30it/s]\n",
      "epoch 160 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.28it/s]\n",
      "epoch 161 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.53it/s]\n",
      "epoch 162 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.26it/s]\n",
      "epoch 163 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "epoch 164 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.52it/s]\n",
      "epoch 165 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.32it/s]\n",
      "epoch 166 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "epoch 167 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.33it/s]\n",
      "epoch 168 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.47it/s]\n",
      "epoch 169 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.20it/s]\n",
      "epoch 170 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.23it/s]\n",
      "epoch 171 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.25it/s]\n",
      "epoch 172 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.26it/s]\n",
      "epoch 173 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.30it/s]\n",
      "epoch 174 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.30it/s]\n",
      "epoch 175 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.34it/s]\n",
      "epoch 176 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.49it/s]\n",
      "epoch 177 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.72it/s]\n",
      "epoch 178 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.39it/s]\n",
      "epoch 179 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.53it/s]\n",
      "epoch 180 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.54it/s]\n",
      "epoch 181 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.24it/s]\n",
      "epoch 182 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.28it/s]\n",
      "epoch 183 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.49it/s]\n",
      "epoch 184 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.39it/s]\n",
      "epoch 185 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.29it/s]\n",
      "epoch 186 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.45it/s]\n",
      "epoch 187 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.75it/s]\n",
      "epoch 188 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.15it/s]\n",
      "epoch 189 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.58it/s]\n",
      "epoch 190 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.23it/s]\n",
      "epoch 191 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.59it/s]\n",
      "epoch 192 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.42it/s]\n",
      "epoch 193 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.26it/s]\n",
      "epoch 194 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.21it/s]\n",
      "epoch 195 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.25it/s]\n",
      "epoch 196 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.45it/s]\n",
      "epoch 197 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.08it/s]\n",
      "epoch 198 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.41it/s]\n",
      "epoch 199 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.26it/s]\n",
      "epoch 200 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.50it/s]\n",
      "epoch 201 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.33it/s]\n",
      "epoch 202 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.30it/s]\n",
      "epoch 203 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.22it/s]\n",
      "epoch 204 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.62it/s]\n",
      "epoch 205 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.35it/s]\n",
      "epoch 206 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.19it/s]\n",
      "epoch 207 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.41it/s]\n",
      "epoch 208 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.44it/s]\n",
      "epoch 209 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.44it/s]\n",
      "epoch 210 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.54it/s]\n",
      "epoch 211 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "epoch 212 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.50it/s]\n",
      "epoch 213 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.55it/s]\n",
      "epoch 214 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.50it/s]\n",
      "epoch 215 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.45it/s]\n",
      "epoch 216 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.82it/s]\n",
      "epoch 217 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.45it/s]\n",
      "epoch 218 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.37it/s]\n",
      "epoch 219 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.37it/s]\n",
      "epoch 220 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.56it/s]\n",
      "epoch 221 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.58it/s]\n",
      "epoch 222 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.28it/s]\n",
      "epoch 223 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.72it/s]\n",
      "epoch 224 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.28it/s]\n",
      "epoch 225 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.36it/s]\n",
      "epoch 226 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.40it/s]\n",
      "epoch 227 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.38it/s]\n",
      "epoch 228 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.31it/s]\n",
      "epoch 229 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.75it/s]\n",
      "epoch 230 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.32it/s]\n",
      "epoch 231 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.43it/s]\n",
      "epoch 232 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.44it/s]\n",
      "epoch 233 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.47it/s]\n",
      "epoch 234 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.38it/s]\n",
      "epoch 235 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.38it/s]\n",
      "epoch 236 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.30it/s]\n",
      "epoch 237 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.16it/s]\n",
      "epoch 238 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.55it/s]\n",
      "epoch 239 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.38it/s]\n",
      "epoch 240 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.60it/s]\n",
      "epoch 241 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.52it/s]\n",
      "epoch 242 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.37it/s]\n",
      "epoch 243 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.30it/s]\n",
      "epoch 244 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.39it/s]\n",
      "epoch 245 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.41it/s]\n",
      "epoch 246 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.39it/s]\n",
      "epoch 247 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.50it/s]\n",
      "epoch 248 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.41it/s]\n",
      "epoch 249 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.49it/s]\n",
      "epoch 250 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.40it/s]\n",
      "epoch 251 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.45it/s]\n",
      "epoch 252 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "epoch 253 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.39it/s]\n",
      "epoch 254 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.40it/s]\n",
      "epoch 255 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.39it/s]\n",
      "epoch 256 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.15it/s]\n",
      "epoch 257 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.56it/s]\n",
      "epoch 258 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.26it/s]\n",
      "epoch 259 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.39it/s]\n",
      "epoch 260 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.54it/s]\n",
      "epoch 261 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.52it/s]\n",
      "epoch 262 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.41it/s]\n",
      "epoch 263 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.20it/s]\n",
      "epoch 264 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "epoch 265 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.52it/s]\n",
      "epoch 266 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.51it/s]\n",
      "epoch 267 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.57it/s]\n",
      "epoch 268 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.32it/s]\n",
      "epoch 269 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.46it/s]\n",
      "epoch 270 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.42it/s]\n",
      "epoch 271 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.54it/s]\n",
      "epoch 272 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.24it/s]\n",
      "epoch 273 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.29it/s]\n",
      "epoch 274 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.08it/s]\n",
      "epoch 275 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.38it/s]\n",
      "epoch 276 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.15it/s]\n",
      "epoch 277 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.36it/s]\n",
      "epoch 278 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.34it/s]\n",
      "epoch 279 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.62it/s]\n",
      "epoch 280 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.24it/s]\n",
      "epoch 281 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.24it/s]\n",
      "epoch 282 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.35it/s]\n",
      "epoch 283 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.47it/s]\n",
      "epoch 284 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.61it/s]\n",
      "epoch 285 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.52it/s]\n",
      "epoch 286 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.44it/s]\n",
      "epoch 287 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.25it/s]\n",
      "epoch 288 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.55it/s]\n",
      "epoch 289 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.32it/s]\n",
      "epoch 290 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.25it/s]\n",
      "epoch 291 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.38it/s]\n",
      "epoch 292 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.38it/s]\n",
      "epoch 293 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "epoch 294 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "epoch 295 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.32it/s]\n",
      "epoch 296 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.62it/s]\n",
      "epoch 297 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.36it/s]\n",
      "epoch 298 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.29it/s]\n",
      "epoch 299 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.47it/s]\n",
      "epoch 300 batch: 100%|████████████████████████████| 1/1 [00:19<00:00, 19.40s/it]\n",
      "epoch 301 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.77it/s]\n",
      "epoch 302 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.32it/s]\n",
      "epoch 303 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.10it/s]\n",
      "epoch 304 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "epoch 305 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.07it/s]\n",
      "epoch 306 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.41it/s]\n",
      "epoch 307 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.43it/s]\n",
      "epoch 308 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.29it/s]\n",
      "epoch 309 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.37it/s]\n",
      "epoch 310 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.38it/s]\n",
      "epoch 311 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.51it/s]\n",
      "epoch 312 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.52it/s]\n",
      "epoch 313 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.25it/s]\n",
      "epoch 314 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "epoch 315 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.55it/s]\n",
      "epoch 316 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.22it/s]\n",
      "epoch 317 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.50it/s]\n",
      "epoch 318 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.32it/s]\n",
      "epoch 319 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.18it/s]\n",
      "epoch 320 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.43it/s]\n",
      "epoch 321 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.53it/s]\n",
      "epoch 322 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.44it/s]\n",
      "epoch 323 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.44it/s]\n",
      "epoch 324 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.35it/s]\n",
      "epoch 325 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.35it/s]\n",
      "epoch 326 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.46it/s]\n",
      "epoch 327 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.29it/s]\n",
      "epoch 328 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.07it/s]\n",
      "epoch 329 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.52it/s]\n",
      "epoch 330 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "epoch 331 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.28it/s]\n",
      "epoch 332 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  3.80it/s]\n",
      "epoch 333 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.35it/s]\n",
      "epoch 334 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.45it/s]\n",
      "epoch 335 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.43it/s]\n",
      "epoch 336 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.22it/s]\n",
      "epoch 337 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.31it/s]\n",
      "epoch 338 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "epoch 339 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.62it/s]\n",
      "epoch 340 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.42it/s]\n",
      "epoch 341 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.29it/s]\n",
      "epoch 342 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.48it/s]\n",
      "epoch 343 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.08it/s]\n",
      "epoch 344 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.19it/s]\n",
      "epoch 345 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.13it/s]\n",
      "epoch 346 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.25it/s]\n",
      "epoch 347 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.39it/s]\n",
      "epoch 348 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.47it/s]\n",
      "epoch 349 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.21it/s]\n",
      "epoch 350 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.39it/s]\n",
      "epoch 351 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.30it/s]\n",
      "epoch 352 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.30it/s]\n",
      "epoch 353 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.39it/s]\n",
      "epoch 354 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.47it/s]\n",
      "epoch 355 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.45it/s]\n",
      "epoch 356 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.16it/s]\n",
      "epoch 357 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.36it/s]\n",
      "epoch 358 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.07it/s]\n",
      "epoch 359 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.41it/s]\n",
      "epoch 360 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.42it/s]\n",
      "epoch 361 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.32it/s]\n",
      "epoch 362 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.40it/s]\n",
      "epoch 363 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.15it/s]\n",
      "epoch 364 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.47it/s]\n",
      "epoch 365 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.36it/s]\n",
      "epoch 366 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.05it/s]\n",
      "epoch 367 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "epoch 368 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.14it/s]\n",
      "epoch 369 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.14it/s]\n",
      "epoch 370 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.53it/s]\n",
      "epoch 371 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.38it/s]\n",
      "epoch 372 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.55it/s]\n",
      "epoch 373 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.22it/s]\n",
      "epoch 374 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.62it/s]\n",
      "epoch 375 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.34it/s]\n",
      "epoch 376 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.27it/s]\n",
      "epoch 377 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.35it/s]\n",
      "epoch 378 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.82it/s]\n",
      "epoch 379 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.11it/s]\n",
      "epoch 380 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.65it/s]\n",
      "epoch 381 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  3.87it/s]\n",
      "epoch 382 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  3.81it/s]\n",
      "epoch 383 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  3.67it/s]\n",
      "epoch 384 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  3.84it/s]\n",
      "epoch 385 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  3.74it/s]\n",
      "epoch 386 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  3.99it/s]\n",
      "epoch 387 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  3.84it/s]\n",
      "epoch 388 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  3.89it/s]\n",
      "epoch 389 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.35it/s]\n",
      "epoch 390 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.26it/s]\n",
      "epoch 391 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  3.99it/s]\n",
      "epoch 392 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  2.84it/s]\n",
      "epoch 393 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.28it/s]\n",
      "epoch 394 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  4.24it/s]\n",
      "epoch 395 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  3.73it/s]\n",
      "epoch 396 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  3.97it/s]\n",
      "epoch 397 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  3.74it/s]\n",
      "epoch 398 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  3.63it/s]\n",
      "epoch 399 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  3.84it/s]\n",
      "epoch 400 batch: 100%|████████████████████████████| 1/1 [00:00<00:00,  3.93it/s]\n"
     ]
    }
   ],
   "source": [
    "!python trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a12cf20-c679-4c15-93e8-d82243c1f94c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] 당신은 누구입니까?[SEP]'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kobert_tokenizer import KoBERTTokenizer\n",
    "tokenizer = KoBERTTokenizer.from_pretrained(\"skt/kobert-base-v1\")\n",
    "tokenizer.decode([2, 1618, 6733, 7086, 1528, 7138, 5771, 258, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "39d453d3-fc22-4206-90e1-5a1c99921430",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexing: 1it [00:00,  1.49it/s]\n"
     ]
    }
   ],
   "source": [
    "!python index_runner.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c9325df1-6c6c-45b0-91d3-dc46c2ef1269",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!export CUDA_LAUNCH_BLOCKING=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "601b3c1d-2941-4364-af11-dd6d6b4d7a3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n",
      "{'passage0': '일 일 일 일 일 일 일 일 일 일 일 일', 'sim0': 148.86117553710938, 'passage1': '팔 팔 팔 팔 팔 팔 팔 팔 팔 팔 팔 팔', 'sim1': 145.4346923828125, 'passage2': '육 육 육 육 육 육 육 육 육 육 육 육', 'sim2': 144.63687133789062, 'passage3': '영 영 영 영 영 영 영 영 영 영 영 영', 'sim3': 143.29876708984375, 'passage4': '사 사 사 사 사 사 사 사 사 사 사 사', 'sim4': 142.65452575683594, 'passage5': '삼 삼 삼 삼 삼 삼 삼 삼 삼 삼 삼 삼', 'sim5': 142.02813720703125}\n"
     ]
    }
   ],
   "source": [
    "!python retriever.py -q \"일 일 일 일 일 일 일\" -k 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac9ec720-3a9a-473e-a7f1-3290776506c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLNetTokenizer'. \n",
      "The class this function is called from is 'KoBERTTokenizer'.\n",
      "{'passage0': '팔 팔 팔 팔 팔 팔 팔 팔 팔 팔 팔 팔', 'sim0': 102.9710922241211, 'passage1': '사 사 사 사 사 사 사 사 사 사 사 사', 'sim1': 99.55248260498047, 'passage2': '영 영 영 영 영 영 영 영 영 영 영 영', 'sim2': 97.54780578613281, 'passage3': '육 육 육 육 육 육 육 육 육 육 육 육', 'sim3': 94.1820068359375, 'passage4': '일 일 일 일 일 일 일 일 일 일 일 일', 'sim4': 86.196533203125, 'passage5': '칠 칠 칠 칠 칠 칠 칠 칠 칠 칠 칠 칠', 'sim5': 66.88600158691406}\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d59a395-12e8-4711-b609-a6a909d18ad7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
