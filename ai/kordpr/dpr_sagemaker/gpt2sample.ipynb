{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d80823",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, IPython\n",
    "\n",
    "install_needed = True\n",
    "#install_needed = False\n",
    "\n",
    "if install_needed:\n",
    "    print(\"===> Installing deps and restarting kernel. Please change 'install_needed = False' and run this code cell again.\")\n",
    "    !{sys.executable} -m pip install -U sagemaker locust pyngrok torch==1.11 transformers==4.17\n",
    "    #IPython.Application.instance().kernel.do_shutdown(True)\n",
    "else:\n",
    "    import sagemaker, transformers, torch\n",
    "    print(f'SageMaker API version={sagemaker.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0e0da27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun  5 00:43:45 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.161.08             Driver Version: 535.161.08   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       On  | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   25C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61cb4502",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "('sagemaker-ap-northeast-2-095298771240', 'arn:aws:iam::095298771240:role/service-role/AmazonSageMaker-ExecutionRole-20240603T133999', 'ap-northeast-2')\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "# SageMaker 세션과 기본 S3 버킷 초기화\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "\n",
    "# Boto3를 통한 SageMaker 클라이언트 설정\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "# 실행 역할 및 리전 설정\n",
    "role = sagemaker.get_execution_role()\n",
    "boto_session = boto3.session.Session()\n",
    "region = boto_session.region_name\n",
    "\n",
    "# 확인을 위한 출력\n",
    "print((bucket, role, region))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe0db74c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/kordpr/dpr_sagemaker\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0b2433c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# # 모델과 토크나이저 다운로드\n",
    "# model_name = 'gpt2'\n",
    "# model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "# tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# # 로컬 디렉터리에 저장\n",
    "model_dir = \"../../kordpr\"\n",
    "# os.makedirs(model_dir, exist_ok=True)\n",
    "# model.save_pretrained(model_dir)\n",
    "# tokenizer.save_pretrained(model_dir)\n",
    "\n",
    "# tar.gz 파일로 압축\n",
    "with tarfile.open('model.tar.gz', 'w:gz') as tar:\n",
    "    for file_name in os.listdir(model_dir):\n",
    "        tar.add(os.path.join(model_dir, file_name), arcname=file_name)\n",
    "\n",
    "# S3에 업로드\n",
    "import boto3\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = 'dawoncecds3'\n",
    "s3.upload_file('model.tar.gz', bucket_name, 'model.tar.gz')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5c66f80",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket_name = 'dawoncecds3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24f9ac1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------!"
     ]
    }
   ],
   "source": [
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "# HuggingFaceModel 객체 생성\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    model_data='s3://{}/model.tar.gz'.format(bucket_name),  # S3에 저장된 모델 경로\n",
    "    role=role,  # SageMaker 역할\n",
    "    entry_point='inference.py',  # 모델 및 추론 스크립트 파일\n",
    "    transformers_version='4.17',  # 트랜스포머 라이브러리 버전\n",
    "    pytorch_version='1.10',  # 파이토치 버전\n",
    "    py_version='py38',  # 파이썬 버전\n",
    "    #image_uri='471112711710.dkr.ecr.ap-northeast-2.amazonaws.com/my_pytorch_repository',\n",
    ")\n",
    "\n",
    "# 엔드포인트 이름을 고정\n",
    "endpoint_name = 'dawoncecdEP'\n",
    "\n",
    "# 엔드포인트 배포\n",
    "predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1, \n",
    "    instance_type='ml.g4dn.xlarge',\n",
    "    endpoint_name=endpoint_name  # 고정된 엔드포인트 이름 지정\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db89d2b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# !pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c6b29bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b2c67d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Package(s) not found: python\u001b[0m\u001b[33m\n",
      "\u001b[0mName: transformers\n",
      "Version: 4.40.2\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: \n",
      "---\n",
      "Name: torch\n",
      "Version: 2.1.0\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages\n",
      "Requires: filelock, fsspec, jinja2, networkx, sympy, typing-extensions\n",
      "Required-by: captum, torchaudio, torchdata, torchtext, torchvision\n"
     ]
    }
   ],
   "source": [
    "# !pip show transformers torch python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1bea39e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.14\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c154e0d0-d86d-4ffd-83df-cca75fe19f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
